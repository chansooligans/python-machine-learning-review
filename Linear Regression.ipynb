{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this is to review Python syntax by fitting\n",
    "a linear regression over simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numpy.linalg import inv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Genearating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "X1 = np.random.normal(1,3,size=1000)\n",
    "X2 = np.random.normal(-3,1,size=1000)\n",
    "epsilon = np.random.normal(0,4,size=1000)\n",
    "y = 2 + 3*X1 - 4*X2 + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe\n",
    "df = pd.DataFrame(\n",
    "    {'X1': X1,\n",
    "     'X2': X2,\n",
    "     'y': y        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat W = \\left( X^T X \\right)^{-1} X^T y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0 = np.repeat(1,X1.size)\n",
    "X = np.vstack((X0,X1,X2)).T\n",
    "Xt = np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.90249596,  2.9570328 , -4.05909316])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(inv(np.dot(Xt,X)), np.dot(Xt,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lm.fit(df[['X1','X2']],df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.90249595997\n",
      "[ 2.9570328  -4.05909316]\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow\n",
    "\n",
    "Using gradient descent\n",
    "\n",
    "Newton's Method:\n",
    "$$ W^* = W - \\left. \\frac{dL}{dW} \\middle/ \\frac{d^2 L}{dW^2} \\right. $$\n",
    "\n",
    "For gradient descent, assume that we can calculate first derivative, but not the second derivative.\n",
    "$$ W^* = W - \\eta \\frac{dL}{dW} $$\n",
    "\n",
    "where $\\eta$ is called the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_vars():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "reset_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([[0.0],[0.0]], name='weight')\n",
    "b = tf.Variable([0.0], name = 'bias')\n",
    "x = tf.placeholder(shape=[None, 2], dtype=tf.float32, name='x')\n",
    "y_label = tf.placeholder(shape=[None, 1], dtype=tf.float32, name='y_label')\n",
    "y_ = tf.matmul(x, W) + b\n",
    "loss = tf.reduce_mean(tf.square(y_ - y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = tf.constant(0.05, name='learning_rate')\n",
    "iterate_W = W.assign(W - eta * tf.gradients(loss, W)[0])\n",
    "iterate_b = b.assign(b - eta * tf.gradients(loss, b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.4344\n",
      "19.2971\n",
      "15.8188\n",
      "15.4638\n",
      "15.4272\n",
      "15.423\n",
      "15.4221\n",
      "15.4216\n",
      "15.4211\n",
      "15.4206\n",
      "15.4201\n",
      "15.4197\n",
      "15.4192\n",
      "15.4188\n",
      "15.4183\n",
      "15.4179\n",
      "15.4175\n",
      "15.417\n",
      "15.4166\n",
      "15.4162\n",
      "15.4158\n",
      "15.4154\n",
      "15.4151\n",
      "15.4147\n",
      "15.4143\n",
      "15.4139\n",
      "15.4136\n",
      "15.4132\n",
      "15.4129\n",
      "15.4125\n",
      "15.4122\n",
      "15.4119\n",
      "15.4116\n",
      "15.4112\n",
      "15.4109\n",
      "15.4106\n",
      "15.4103\n",
      "15.41\n",
      "15.4097\n",
      "15.4095\n",
      "15.4092\n",
      "15.4089\n",
      "15.4086\n",
      "15.4084\n",
      "15.4081\n",
      "15.4078\n",
      "15.4076\n",
      "15.4073\n",
      "15.4071\n",
      "15.4068\n",
      "15.4066\n",
      "15.4064\n",
      "15.4061\n",
      "15.4059\n",
      "15.4057\n",
      "15.4055\n",
      "15.4053\n",
      "15.405\n",
      "15.4048\n",
      "15.4046\n",
      "15.4044\n",
      "15.4042\n",
      "15.404\n",
      "15.4039\n",
      "15.4037\n",
      "15.4035\n",
      "15.4033\n",
      "15.4031\n",
      "15.4029\n",
      "15.4028\n",
      "15.4026\n",
      "15.4024\n",
      "15.4023\n",
      "15.4021\n",
      "15.402\n",
      "15.4018\n",
      "15.4017\n",
      "15.4015\n",
      "15.4014\n",
      "15.4012\n",
      "15.4011\n",
      "15.4009\n",
      "15.4008\n",
      "15.4007\n",
      "15.4005\n",
      "15.4004\n",
      "15.4003\n",
      "15.4001\n",
      "15.4\n",
      "15.3999\n",
      "15.3998\n",
      "15.3997\n",
      "15.3995\n",
      "15.3994\n",
      "15.3993\n",
      "15.3992\n",
      "15.3991\n",
      "15.399\n",
      "15.3989\n",
      "15.3988\n",
      "15.3987\n",
      "15.3986\n",
      "15.3985\n",
      "15.3984\n",
      "15.3983\n",
      "15.3982\n",
      "15.3981\n",
      "15.398\n",
      "15.3979\n",
      "15.3978\n",
      "15.3977\n",
      "15.3977\n",
      "15.3976\n",
      "15.3975\n",
      "15.3974\n",
      "15.3973\n",
      "15.3973\n",
      "15.3972\n",
      "15.3971\n",
      "15.397\n",
      "15.397\n",
      "15.3969\n",
      "15.3968\n",
      "15.3968\n",
      "15.3967\n",
      "15.3966\n",
      "15.3966\n",
      "15.3965\n",
      "15.3964\n",
      "15.3964\n",
      "15.3963\n",
      "15.3963\n",
      "15.3962\n",
      "15.3961\n",
      "15.3961\n",
      "15.396\n",
      "15.396\n",
      "15.3959\n",
      "15.3959\n",
      "15.3958\n",
      "15.3958\n",
      "15.3957\n",
      "15.3957\n",
      "15.3956\n",
      "15.3956\n",
      "15.3955\n",
      "15.3955\n",
      "15.3954\n",
      "15.3954\n",
      "15.3953\n",
      "15.3953\n",
      "15.3952\n",
      "15.3952\n",
      "15.3952\n",
      "15.3951\n",
      "15.3951\n",
      "15.395\n",
      "15.395\n",
      "15.395\n",
      "15.3949\n",
      "15.3949\n",
      "15.3949\n",
      "15.3948\n",
      "15.3948\n",
      "15.3948\n",
      "15.3947\n",
      "15.3947\n",
      "15.3947\n",
      "15.3946\n",
      "15.3946\n",
      "15.3946\n",
      "15.3945\n",
      "15.3945\n",
      "15.3945\n",
      "15.3944\n",
      "15.3944\n",
      "15.3944\n",
      "15.3944\n",
      "15.3943\n",
      "15.3943\n",
      "15.3943\n",
      "15.3943\n",
      "15.3942\n",
      "15.3942\n",
      "15.3942\n",
      "15.3942\n",
      "15.3941\n",
      "15.3941\n",
      "15.3941\n",
      "15.3941\n",
      "15.394\n",
      "15.394\n",
      "15.394\n",
      "15.394\n",
      "15.394\n",
      "15.3939\n",
      "15.3939\n",
      "15.3939\n",
      "15.3939\n",
      "15.3939\n"
     ]
    }
   ],
   "source": [
    "reset_vars()\n",
    "\n",
    "for i in range(200):\n",
    "    j = np.random.randint(len(y))\n",
    "    sess.run([iterate_W, iterate_b], feed_dict = {x: np.vstack((X1,X2)).T,\n",
    "                                                 y_label: y.reshape(-1,1)})\n",
    "    print(sess.run(loss, feed_dict={x: np.vstack((X1,X2)).T,\n",
    "                                                 y_label: y.reshape(-1,1)}))\n",
    "    \n",
    "#.reshape(-1,1) is used to reshape numpy array so that it has 2 dimensions; equivalent to saying (none,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_val = sess.run(W)\n",
    "b_val = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.79411328]\n",
      "[[ 2.95760846]\n",
      " [-4.09207678]]\n"
     ]
    }
   ],
   "source": [
    "print(b_val)\n",
    "print(W_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
